{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import numpy as np\n",
    "from dateutil.parser import parse as dateparse\n",
    "from lat_lon_parser import parse as parse\n",
    "import json\n",
    "import re\n",
    "import reverse_geocode as rg\n",
    "\n",
    "############## Accès S3 quand ça marchera ############\n",
    "#from pyarrow import fs\n",
    "#\n",
    "#s3fs = fs.S3FileSystem(\n",
    "#    endpoint_override=\"localhost:9000\",\n",
    "#    access_key=\"lbIwWP4FIBtjBwU5AaI0\",\n",
    "#    secret_key=\"nw54mjkG3CjxjvkyqxACTbYOuhtzyc1YmkMaJXeL\",\n",
    "#    scheme=\"http\"\n",
    "#)\n",
    "#\n",
    "#s3fs.get_file_info('geo-sra/sra')\n",
    "######################################################\n",
    "\n",
    "df = pd.read_parquet(\"/Users/tpietav/Desktop/data/raw/sra_metadata_toy.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_date(string, fuzzy=False):\n",
    "    \"\"\"\n",
    "    Return whether the string can be interpreted as a date.\n",
    "\n",
    "    :param string: str, string to check for date\n",
    "    :param fuzzy: bool, ignore unknown tokens in string if True\n",
    "    \"\"\"\n",
    "    try: \n",
    "        dateparse(string, fuzzy=fuzzy)\n",
    "        return True\n",
    "\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_first_collection_date(x):\n",
    "    if not pd.isnull(x):\n",
    "        return x[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "df[\"collection_date\"] = df['collection_date_sam'].apply(select_first_collection_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_alpha_string(string,max_words=2):\n",
    "    \"\"\"\n",
    "    Return wether a string is an alpha string or not\n",
    "\n",
    "    Args:\n",
    "        string (String): string to check \n",
    "        max_words (int, optional): max words that can contain the string. Defaults to 2.\n",
    "    \"\"\"\n",
    "    for n in range(max_words):\n",
    "        pattern = r'^[a-zA-Z]+ {'+str(n)+r'}[a-zA-Z]+$'\n",
    "        if re.match(pattern,string):\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decimal_precision(nombre):\n",
    "    if nombre == np.NaN:\n",
    "        return np.NaN\n",
    "    chaine = str(nombre)\n",
    "    index_point = chaine.find('.')\n",
    "    if index_point == -1:\n",
    "        return np.NaN\n",
    "    return len(chaine) - index_point - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_is_na(country):\n",
    "    \"\"\"\n",
    "    Return wether a country field is NA or not\n",
    "\n",
    "    Args:\n",
    "        country (string): Country value\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the string is Na False if not\n",
    "    \"\"\"\n",
    "    country_na_tag = ['uncalculated','<NA>']\n",
    "    if pd.isna(country):\n",
    "        return True\n",
    "    elif country in country_na_tag:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#START - Parse data\n",
      "num_partitions 11 ----\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "num_partitions = multiprocessing.cpu_count()\n",
    "\n",
    "print('#START - Parse data')\n",
    "print('num_partitions',num_partitions,'----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as ddf\n",
    "\n",
    "dask = ddf.from_pandas(df, npartitions=num_partitions-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "columns = ['bioproject', 'acc','organism','assay_type','instrument','librarylayout','libraryselection','librarysource','geo_loc_name_country_calc','geo_loc_name_country_continent_calc','mbytes','mbases','releasedate', 'collection_date','lat_lon_src','lat_lon_raw','latitude','longitude','latitude_precision','has_latlon','longitude_precision','rg_country_code','rg_city','rg_country','GEO_QUAL']\n",
    "dtype = [str,str,str,str,str,str,str,str,str,str,int,int,datetime.date,datetime.date,str,str,float,float,float,float,bool,str,str,str,int]\n",
    "cdt={i[0]: i[1] for i in zip(columns, dtype)}\n",
    "meta_df = pd.DataFrame(columns=list(cdt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lat Lon Tag': 280107, 'Lat Tag': 22640, 'Lon Tag': 22410, 'No Tag': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TAGS TEST\n",
    "\n",
    "dic = {\n",
    "    \"Lat Lon Tag\":0,\n",
    "    \"Lat Tag\"    :0,\n",
    "    \"Lon Tag\"    :0,\n",
    "    \"No Tag\"     :0\n",
    "}\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "# \n",
    "# selected tag\n",
    "#\n",
    "\n",
    "lat_lon_tag = ['lat_lon_sam_s_dpl34','lat_lon_sam_s_dpl1','geographic_location__latitude_and_longitude__sam','geographic_location__latitudeandlongitude__sam','latitude__and_longitude_sam','latitude_and_longitude_sam','lattitude_and_logitude_sam','lat_lon_sam','latlon_sam','location_coordinates_sam','other_gps_coordinates_sam','lat_lon_dms_sam','lat_long_correct_sam','lat_lon_run']\n",
    "\n",
    "lat_tag = ['geographic_location__latitude__sam_s_dpl4','lat_lon_sam_s_dpl1','latitude_sam','lat_sam','geographic_location__latitude__sam','geographiclocation_latitude__sam','latitude_dd_sam','latitude_deg_sam','biological_material_latitude_sam']\n",
    "\n",
    "lon_tag = ['geographic_location__longitude__sam_s_dpl5','longitude_sam','lon_sam','geographic_location__longitude__sam','longitude_dd_sam','longitude_deg_sam','biological_material_longitude_sam']\n",
    "        \n",
    "filtered_tag = np.concatenate((lat_lon_tag,lat_tag,lon_tag))\n",
    "\n",
    "for samples in dask.itertuples(index=False):\n",
    "     \n",
    "    # Problem of serialization between dask partition / pandas\n",
    "    # attributes = samples.attributes\n",
    "    # attributes_df = pd.DataFrame.from_records(attributes)\n",
    "\n",
    "    attributes = samples.jattr\n",
    "\n",
    "    if(not attributes==\"\"):\n",
    "\n",
    "        attributes_df = pd.DataFrame(json.loads(attributes).items(),columns=['k', 'v'])\n",
    "\n",
    "    else:\n",
    "        \n",
    "        attributes_df=pd.DataFrame()\n",
    "        print(\"ERROR EMPTY\")\n",
    "\n",
    "    if('k' in attributes_df):\n",
    "            \n",
    "            attributes_df = attributes_df.loc[attributes_df['k'].isin(filtered_tag)]\n",
    "\n",
    "            for index, attribute in attributes_df.iterrows():\n",
    "                \n",
    "                #store attributes keyword\n",
    "\n",
    "                #if attribute['k'] in dict_attributes_k :\n",
    "                #    dict_attributes_k[attribute['k']] = dict_attributes_k[attribute['k']] + 1\n",
    "                #else :\n",
    "                #    dict_attributes_k[attribute['k']] = 0\n",
    "                #    print(\"keyword\", attribute['k'])\n",
    "\n",
    "                ###########################################################################\n",
    "                # latitude - longitude in the same field\n",
    "\n",
    "                lat_lon_list = None\n",
    "\n",
    "                if attribute['k'] in lat_lon_tag : \n",
    "                    dic[\"Lat Lon Tag\"] += 1\n",
    "                if attribute['k'] in lat_tag:\n",
    "                    dic['Lat Tag'] += 1\n",
    "                if attribute['k'] in lon_tag:\n",
    "                    dic['Lon Tag'] += 1\n",
    "                if not ((attribute['k'] in lat_lon_tag) or (attribute['k'] in lat_tag) or (attribute['k'] in lon_tag)):\n",
    "                    dic['No Tag'] += 1\n",
    "\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Match': 239553, 'Alpha String': 39424, 'No Match': 1130, 'Tot': 280107}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LAT LON PATTERNS TEST\n",
    "\n",
    "lat_lon_patterns = [\n",
    "    r\"(-?\\d+\\.\\d+ [NS]) (-?\\d+\\.\\d+ [WE])\",   # xx.xxx N xx.xxx W\n",
    "    r\"(-?\\d+\\.\\d+' [NS]) (-?\\d+\\.\\d+' [WE])\", # xx.xxx' N xx.xxx' W\n",
    "    r\"(-?\\d+\\.\\d+° [NS]) (-?\\d+\\.\\d+° [WE])\", # xx.xxx° N xx.xxx° W\n",
    "    r'(-?\\d+ [NS]) (-?\\d+ [WE])',             # xx N xx W\n",
    "    r'(-?\\d+\\.\\d+ [NS]) (-?\\d+ [WE])',        # xx.xxx N xx W\n",
    "    r'(-?\\d+ [NS]) (-?\\d+\\.\\d+ [WE])',        # xx N xx.xxx W \n",
    "    r'(-?\\d+\\.\\d+) (-?\\d+\\.\\d+)',             # xx.xxx xx.xxx\n",
    "    r'(-?\\d+\\.\\d+°) (-?\\d+\\.\\d+°)',           # xx.xxx° xx.xxx°\n",
    "    r\"(-?\\d+\\.\\d+') (-?\\d+\\.\\d+')\",           # xx.xxx' xx.xxx'\n",
    "]\n",
    "\n",
    "dic = {\n",
    "    \"Match\"       :0,\n",
    "    \"Alpha String\":0,\n",
    "    \"No Match\"   :0,\n",
    "    \"Tot\"         :0\n",
    "}\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "# \n",
    "# selected tag\n",
    "#\n",
    "\n",
    "lat_lon_tag = ['lat_lon_sam_s_dpl34','lat_lon_sam_s_dpl1','geographic_location__latitude_and_longitude__sam','geographic_location__latitudeandlongitude__sam','latitude__and_longitude_sam','latitude_and_longitude_sam','lattitude_and_logitude_sam','lat_lon_sam','latlon_sam','location_coordinates_sam','other_gps_coordinates_sam','lat_lon_dms_sam','lat_long_correct_sam','lat_lon_run']\n",
    "\n",
    "lat_tag = ['geographic_location__latitude__sam_s_dpl4','lat_lon_sam_s_dpl1','latitude_sam','lat_sam','geographic_location__latitude__sam','geographiclocation_latitude__sam','latitude_dd_sam','latitude_deg_sam','biological_material_latitude_sam']\n",
    "\n",
    "lon_tag = ['geographic_location__longitude__sam_s_dpl5','longitude_sam','lon_sam','geographic_location__longitude__sam','longitude_dd_sam','longitude_deg_sam','biological_material_longitude_sam']\n",
    "        \n",
    "filtered_tag = np.concatenate((lat_lon_tag,lat_tag,lon_tag))\n",
    "\n",
    "for samples in dask.itertuples(index=False):\n",
    "     \n",
    "    # Problem of serialization between dask partition / pandas\n",
    "    # attributes = samples.attributes\n",
    "    # attributes_df = pd.DataFrame.from_records(attributes)\n",
    "\n",
    "    attributes = samples.jattr\n",
    "\n",
    "    if(not attributes==\"\"):\n",
    "\n",
    "        attributes_df = pd.DataFrame(json.loads(attributes).items(),columns=['k', 'v'])\n",
    "\n",
    "    else:\n",
    "        \n",
    "        attributes_df=pd.DataFrame()\n",
    "        print(\"ERROR EMPTY\")\n",
    "\n",
    "    if('k' in attributes_df):\n",
    "            \n",
    "            attributes_df = attributes_df.loc[attributes_df['k'].isin(filtered_tag)]\n",
    "\n",
    "            for index, attribute in attributes_df.iterrows():\n",
    "                \n",
    "                #store attributes keyword\n",
    "\n",
    "                #if attribute['k'] in dict_attributes_k :\n",
    "                #    dict_attributes_k[attribute['k']] = dict_attributes_k[attribute['k']] + 1\n",
    "                #else :\n",
    "                #    dict_attributes_k[attribute['k']] = 0\n",
    "                #    print(\"keyword\", attribute['k'])\n",
    "\n",
    "                ###########################################################################\n",
    "                # latitude - longitude in the same field\n",
    "\n",
    "                lat_lon_list = None\n",
    "\n",
    "                if attribute['k'] in lat_lon_tag :\n",
    "\n",
    "                    dic['Tot'] += 1\n",
    "                    \n",
    "                    lat_lon_src = attribute['k']\n",
    "\n",
    "                    if(isinstance(attribute['v'], list)):\n",
    "                        lat_lon = attribute['v'][0]\n",
    "                    else:\n",
    "                        lat_lon = attribute['v']\n",
    "\n",
    "                    if not is_alpha_string(str(lat_lon)):\n",
    "                        str_lat_lon = str(lat_lon)\n",
    "                        for pattern in lat_lon_patterns:\n",
    "                            if re.match(pattern,str_lat_lon):\n",
    "                                dic['Match'] += 1\n",
    "                                lat_lon_list = re.match(pattern,str_lat_lon)\n",
    "                        if lat_lon_list is None:\n",
    "                            dic['No Match'] += 1\n",
    "                    else:\n",
    "                        dic['Alpha String'] += 1\n",
    "\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lon & Lat Match': 19234,\n",
       " 'Lon Match': 98,\n",
       " 'Lat Match': 372,\n",
       " 'No Match': 2622,\n",
       " 'Incomplete': 230}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LAT & LON PATTERNS TEST\n",
    "\n",
    "lat_patterns = [\n",
    "    r\"(-?\\d+\\.\\d+ [NS])\",   # xx.xxx N xx.xxx W\n",
    "    r\"(-?\\d+\\.\\d+' [NS])\",  # xx.xxx' N xx.xxx' W\n",
    "    r\"(-?\\d+\\.\\d+° [NS])\",  # xx.xxx° N xx.xxx° W\n",
    "    r'(-?\\d+ [NS])',             # xx N xx W\n",
    "    r'(-?\\d+\\.\\d+ [NS])',        # xx.xxx N xx W\n",
    "    r'(-?\\d+\\.\\d+)',             # xx.xxx xx.xxx\n",
    "    r'(-?\\d+\\.\\d+°)',           # xx.xxx° xx.xxx°\n",
    "    r\"(-?\\d+\\.\\d+')\",           # xx.xxx' xx.xxx'\n",
    "]\n",
    "\n",
    "lon_patterns = [\n",
    "    r\"(-?\\d+\\.\\d+ [WE])\",\n",
    "    r\"(-?\\d+\\.\\d+' [WE])\",\n",
    "    r\"(-?\\d+\\.\\d+° [WE])\",\n",
    "    r\"(-?\\d+ [WE])\",\n",
    "    r\"(-?\\d+\\.\\d+ [WE])\",\n",
    "    r\"(-?\\d+\\.\\d+)\",\n",
    "    r\"(-?\\d+\\.\\d+°)\",\n",
    "    r\"(-?\\d+\\.\\d+')\"\n",
    "]\n",
    "\n",
    "dic = {\n",
    "    \"Lon & Lat Match\":0,\n",
    "    \"Lon Match\"      :0,\n",
    "    \"Lat Match\"      :0,\n",
    "    \"No Match\"       :0,\n",
    "    \"Incomplete\"     :0\n",
    "}\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "# \n",
    "# selected tag\n",
    "#\n",
    "\n",
    "lat_lon_tag = ['lat_lon_sam_s_dpl34','lat_lon_sam_s_dpl1','geographic_location__latitude_and_longitude__sam','geographic_location__latitudeandlongitude__sam','latitude__and_longitude_sam','latitude_and_longitude_sam','lattitude_and_logitude_sam','lat_lon_sam','latlon_sam','location_coordinates_sam','other_gps_coordinates_sam','lat_lon_dms_sam','lat_long_correct_sam','lat_lon_run']\n",
    "\n",
    "lat_tag = ['geographic_location__latitude__sam_s_dpl4','lat_lon_sam_s_dpl1','latitude_sam','lat_sam','geographic_location__latitude__sam','geographiclocation_latitude__sam','latitude_dd_sam','latitude_deg_sam','biological_material_latitude_sam']\n",
    "\n",
    "lon_tag = ['geographic_location__longitude__sam_s_dpl5','longitude_sam','lon_sam','geographic_location__longitude__sam','longitude_dd_sam','longitude_deg_sam','biological_material_longitude_sam']\n",
    "        \n",
    "filtered_tag = np.concatenate((lat_lon_tag,lat_tag,lon_tag))\n",
    "\n",
    "for samples in dask.itertuples(index=False):\n",
    "     \n",
    "    # Problem of serialization between dask partition / pandas\n",
    "    # attributes = samples.attributes\n",
    "    # attributes_df = pd.DataFrame.from_records(attributes)\n",
    "\n",
    "    attributes = samples.jattr\n",
    "    match_score = 0\n",
    "\n",
    "    if(not attributes==\"\"):\n",
    "\n",
    "        attributes_df = pd.DataFrame(json.loads(attributes).items(),columns=['k', 'v'])\n",
    "\n",
    "    else:\n",
    "        \n",
    "        attributes_df=pd.DataFrame()\n",
    "        print(\"ERROR EMPTY\")\n",
    "\n",
    "    if('k' in attributes_df):\n",
    "            \n",
    "            attributes_df = attributes_df.loc[attributes_df['k'].isin(filtered_tag)]\n",
    "\n",
    "            for index, attribute in attributes_df.iterrows():\n",
    "\n",
    "                if attribute['k'] in lat_tag :\n",
    "                    match_score += 0.5\n",
    "                    if(isinstance(attribute['v'], list)):\n",
    "                        lat = attribute['v'][0]\n",
    "                    else:\n",
    "                        lat = attribute['v']\n",
    "\n",
    "                    if not is_alpha_string(str(lat)):\n",
    "                        str_lat = str(lat)\n",
    "                        for pattern in lat_patterns:\n",
    "                            if re.match(pattern,str_lat):\n",
    "                                match_score += 1\n",
    "                            \n",
    "                if attribute['k'] in lon_tag :\n",
    "                    match_score += 0.5\n",
    "                    if(isinstance(attribute['v'], list)):\n",
    "                        lon = attribute['v'][0]\n",
    "                    else:\n",
    "                        lon = attribute['v']\n",
    "\n",
    "                    if not is_alpha_string(str(lon)):\n",
    "                        str_lon = str(lon)\n",
    "                        for pattern in lon_patterns:\n",
    "                            if re.match(pattern,str_lon):\n",
    "                                match_score += 2\n",
    "    \n",
    "    if np.floor(match_score) != match_score :\n",
    "        dic['Incomplete'] += 1\n",
    "    elif match_score == 1:\n",
    "        dic['No Match'] += 1\n",
    "    elif match_score == 2:\n",
    "        dic['Lat Match'] += 1\n",
    "    elif match_score == 3:\n",
    "        dic['Lon Match'] += 1\n",
    "    elif match_score == 4:\n",
    "        dic['Lon & Lat Match'] += 1\n",
    "\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_geo_sra(pd_array_partition): \n",
    "\n",
    "    array_result = []\n",
    "\n",
    "    for samples in pd_array_partition.itertuples(index=False):\n",
    "\n",
    "        # initialise variable\n",
    "\n",
    "        lat_lon_src = ''\n",
    "        lat_lon_raw = ''\n",
    "        lat_src = ''\n",
    "        lat_raw = ''\n",
    "\n",
    "        lon_src = ''\n",
    "        lon_raw = ''\n",
    "        \n",
    "        lat_lon = ''\n",
    "        lat = ''\n",
    "        lon = ''\n",
    "        lat_list = None\n",
    "        lon_list = None\n",
    "        lat_lon_list = None\n",
    "\n",
    "        latitude = None\n",
    "        longitude = None\n",
    "\n",
    "        latitude_precision = None\n",
    "        longitude_precision = None\n",
    "\n",
    "        has_latlon = False\n",
    "\n",
    "        geo_qual = 4\n",
    "\n",
    "        #\n",
    "        # parse from metadata available\n",
    "        #\n",
    "\n",
    "        bioproject = samples.bioproject\n",
    "        acc = samples.acc\n",
    "        organism = samples.organism\n",
    "        assay_type = samples.assay_type\n",
    "        instrument = samples.instrument\n",
    "        librarylayout = samples.librarylayout\n",
    "        libraryselection = samples.libraryselection\n",
    "        librarysource = samples.librarysource\n",
    "        geo_loc_name_country_calc = samples.geo_loc_name_country_calc\n",
    "        geo_loc_name_country_continent_calc = samples.geo_loc_name_country_continent_calc\n",
    "        mbytes = samples.mbytes\n",
    "        mbases = samples.mbases\n",
    "\n",
    "        releasedate = None\n",
    "        if( not pd.isnull(samples.releasedate)) :\n",
    "            if(is_date(samples.releasedate)):\n",
    "                 releasedate = pd.to_datetime(samples.releasedate)\n",
    "\n",
    "        collection_date = None\n",
    "        if( not pd.isnull(samples.collection_date)) :\n",
    "            # multiple collection date are sometimes available for the same sample\n",
    "            # take the first one\n",
    "            if(is_date(samples.collection_date)):\n",
    "                collection_date = pd.to_datetime(samples.collection_date)\n",
    "\n",
    "        #print(\"DATE\",acc,collection_date,releasedate)\n",
    "\n",
    "        # \n",
    "        # reverse geocoding\n",
    "        #\n",
    "\n",
    "        rg_country_code = ''\n",
    "        rg_city = ''\n",
    "        rg_country = ''\n",
    "\n",
    "        #\n",
    "        # parse from attributes metadata available\n",
    "        #\n",
    "\n",
    "        lat_lon_patterns = [\n",
    "            r\"(-?\\d+\\.\\d+ [NS]) (-?\\d+\\.\\d+ [WE])\",   # xx.xxx N xx.xxx W\n",
    "            r\"(-?\\d+\\.\\d+' [NS]) (-?\\d+\\.\\d+' [WE])\", # xx.xxx' N xx.xxx' W\n",
    "            r\"(-?\\d+\\.\\d+° [NS]) (-?\\d+\\.\\d+° [WE])\", # xx.xxx° N xx.xxx° W\n",
    "            r'(-?\\d+ [NS]) (-?\\d+ [WE])',             # xx N xx W\n",
    "            r'(-?\\d+\\.\\d+ [NS]) (-?\\d+ [WE])',        # xx.xxx N xx W\n",
    "            r'(-?\\d+ [NS]) (-?\\d+\\.\\d+ [WE])',        # xx N xx.xxx W \n",
    "            r'(-?\\d+\\.\\d+) (-?\\d+\\.\\d+)',             # xx.xxx xx.xxx\n",
    "            r'(-?\\d+\\.\\d+°) (-?\\d+\\.\\d+°)',           # xx.xxx° xx.xxx°\n",
    "            r\"(-?\\d+\\.\\d+') (-?\\d+\\.\\d+')\",           # xx.xxx' xx.xxx'\n",
    "        ]\n",
    "\n",
    "        lat_patterns = [\n",
    "            r\"(-?\\d+\\.\\d+ [NS])\",   # xx.xxx N xx.xxx W\n",
    "            r\"(-?\\d+\\.\\d+' [NS])\",  # xx.xxx' N xx.xxx' W\n",
    "            r\"(-?\\d+\\.\\d+° [NS])\",  # xx.xxx° N xx.xxx° W\n",
    "            r'(-?\\d+ [NS])',             # xx N xx W\n",
    "            r'(-?\\d+\\.\\d+ [NS])',        # xx.xxx N xx W\n",
    "            r'(-?\\d+\\.\\d+)',             # xx.xxx xx.xxx\n",
    "            r'(-?\\d+\\.\\d+°)',           # xx.xxx° xx.xxx°\n",
    "            r\"(-?\\d+\\.\\d+')\",           # xx.xxx' xx.xxx'\n",
    "        ]\n",
    "\n",
    "        lon_patterns = [\n",
    "            r\"(-?\\d+\\.\\d+ [WE])\",\n",
    "            r\"(-?\\d+\\.\\d+' [WE])\",\n",
    "            r\"(-?\\d+\\.\\d+° [WE])\",\n",
    "            r\"(-?\\d+ [WE])\",\n",
    "            r\"(-?\\d+\\.\\d+ [WE])\",\n",
    "            r\"(-?\\d+\\.\\d+)\",\n",
    "            r\"(-?\\d+\\.\\d+°)\",\n",
    "            r\"(-?\\d+\\.\\d+')\"\n",
    "        ]\n",
    "\n",
    "        ###########################################################################\n",
    "        # \n",
    "        # selected tag\n",
    "        #\n",
    "\n",
    "        lat_lon_tag = ['lat_lon_sam_s_dpl34','lat_lon_sam_s_dpl1','geographic_location__latitude_and_longitude__sam','geographic_location__latitudeandlongitude__sam','latitude__and_longitude_sam','latitude_and_longitude_sam','lattitude_and_logitude_sam','lat_lon_sam','latlon_sam','location_coordinates_sam','other_gps_coordinates_sam','lat_lon_dms_sam','lat_long_correct_sam','lat_lon_run']\n",
    "\n",
    "        lat_tag = ['geographic_location__latitude__sam_s_dpl4','lat_lon_sam_s_dpl1','latitude_sam','lat_sam','geographic_location__latitude__sam','geographiclocation_latitude__sam','latitude_dd_sam','latitude_deg_sam','biological_material_latitude_sam']\n",
    "\n",
    "        lon_tag = ['geographic_location__longitude__sam_s_dpl5','longitude_sam','lon_sam','geographic_location__longitude__sam','longitude_dd_sam','longitude_deg_sam','biological_material_longitude_sam']\n",
    "        \n",
    "        filtered_tag = np.concatenate((lat_lon_tag,lat_tag,lon_tag))\n",
    "\n",
    "        # Problem of serialization between dask partition / pandas\n",
    "        # attributes = samples.attributes\n",
    "        # attributes_df = pd.DataFrame.from_records(attributes)\n",
    "\n",
    "\n",
    "        attributes = samples.jattr\n",
    "\n",
    "        if(not attributes==\"\"):\n",
    "\n",
    "            attributes_df = pd.DataFrame(json.loads(attributes).items(),columns=['k', 'v'])\n",
    "\n",
    "        else:\n",
    "            attributes_df=pd.DataFrame()\n",
    "            print(\"ERROR EMPTY\")\n",
    "\n",
    "        ###########################################################################\n",
    "        \n",
    "        if('k' in attributes_df):\n",
    "            \n",
    "            attributes_df = attributes_df.loc[attributes_df['k'].isin(filtered_tag)]\n",
    "\n",
    "            for index, attribute in attributes_df.iterrows():\n",
    "                \n",
    "                #store attributes keyword\n",
    "\n",
    "                #if attribute['k'] in dict_attributes_k :\n",
    "                #    dict_attributes_k[attribute['k']] = dict_attributes_k[attribute['k']] + 1\n",
    "                #else :\n",
    "                #    dict_attributes_k[attribute['k']] = 0\n",
    "                #    print(\"keyword\", attribute['k'])\n",
    "\n",
    "                ###########################################################################\n",
    "                # latitude - longitude in the same field\n",
    "\n",
    "\n",
    "                if attribute['k'] in lat_lon_tag :\n",
    "                    \n",
    "                    lat_lon_src = attribute['k']\n",
    "\n",
    "                    if(isinstance(attribute['v'], list)):\n",
    "                        lat_lon = attribute['v'][0]\n",
    "                        lat_lon_raw = attribute['v'][0]\n",
    "                    else:\n",
    "                        lat_lon = attribute['v']\n",
    "                        lat_lon_raw = attribute['v']\n",
    "\n",
    "                    if not is_alpha_string(str(lat_lon)):\n",
    "                        for pattern in lat_lon_patterns:\n",
    "                            if re.match(pattern,str(lat_lon)):\n",
    "                                lat_lon_list = re.match(pattern,str(lat_lon))\n",
    "\n",
    "                ###########################################################################\n",
    "\n",
    "                ###########################################################################\n",
    "                # latitude - longitude in separated fields\n",
    "\n",
    "                # latitude\n",
    "\n",
    "                if attribute['k'] in lat_tag :\n",
    "                    \n",
    "                    lat_src = attribute['k']\n",
    "\n",
    "                    if(isinstance(attribute['v'], list)):\n",
    "                        lat = attribute['v'][0]\n",
    "                        lat_raw = attribute['v'][0]\n",
    "                    else:\n",
    "                        lat = attribute['v']\n",
    "                        lat_raw = attribute['v']\n",
    "\n",
    "                    if lat_lon_src == '':\n",
    "                        lat_lon_src = lat_src\n",
    "                        lat_lon_raw = lat_raw\n",
    "                    else:\n",
    "                        lat_lon_src = lat_src + \" \" + lat_lon_src\n",
    "                        lat_lon_raw = str(lat_raw) + \" \" + lat_lon_raw\n",
    "\n",
    "                    if not is_alpha_string(str(lat)) :\n",
    "                        for pattern in lat_patterns:\n",
    "                            if re.match(pattern,str(lat)):\n",
    "                                lat_list = re.match(pattern,str(lat))\n",
    "\n",
    "                # longitude\n",
    "                \n",
    "                if attribute['k'] in lon_tag :\n",
    "                    \n",
    "                    lon_src = attribute['k']\n",
    "                    \n",
    "                    if(isinstance(attribute['v'], list)):\n",
    "                        lon = attribute['v'][0]\n",
    "                        lon_raw = attribute['v'][0]\n",
    "                    else:\n",
    "                        lon = attribute['v']\n",
    "                        lon_raw = attribute['v']\n",
    "                    \n",
    "                    if lat_lon_src == '':\n",
    "                        lat_lon_src = lon_src\n",
    "                        lat_lon_raw = lon_raw\n",
    "                    else:\n",
    "                        lat_lon_src = lat_lon_src + \" \" + lon_src\n",
    "                        lat_lon_raw = lat_lon_raw + \" \" + str(lon_raw)\n",
    "\n",
    "                    if not is_alpha_string(str(lon)) :\n",
    "                        for pattern in lon_patterns:\n",
    "                            if re.match(pattern,str(lon)):\n",
    "                                lon_list = re.match(pattern,str(lon))\n",
    "                \n",
    "                ###########################################################################\n",
    "\n",
    "            ###########################################################################\n",
    "                \n",
    "            #\n",
    "            # lat_lon_parser\n",
    "            #\n",
    "\n",
    "            if lat_lon_list is not None :\n",
    "\n",
    "                try :\n",
    "                    latitude = parse(lat_lon_list.group(1))\n",
    "                    longitude = parse(lat_lon_list.group(2))\n",
    "                    latitude_precision = decimal_precision(latitude)\n",
    "                    longitude_precision = decimal_precision(longitude)\n",
    "                except:\n",
    "                    #print(\"parse ERROR\", acc,lat_lon)\n",
    "                    pass\n",
    "\n",
    "            if (lon_list is not None) & (lat_list is not None) & (str(lon).count(\".\") <=1) & (str(lat).count(\".\") <=1) :\n",
    "\n",
    "                if (lon_list.group(1) is not None) & (lat_list.group(1) is not None) :\n",
    "\n",
    "                    try :\n",
    "                        latitude = parse(lat_list.group(1))\n",
    "                        longitude = parse(lon_list.group(1))\n",
    "                        latitude_precision = decimal_precision(latitude)\n",
    "                        longitude_precision = decimal_precision(longitude)\n",
    "                    except :\n",
    "                        #print(\"parse ERROR\", acc,lat, lon)\n",
    "                        pass\n",
    "\n",
    "            #\n",
    "            # reverse geocoding\n",
    "            #\n",
    "            \n",
    "            if((latitude is not None) & (longitude is not None)):\n",
    "                coordinates = [(latitude,longitude)]\n",
    "                has_latlon=True\n",
    "                rgeocode = rg.search(coordinates)\n",
    "                \n",
    "                if(len(rgeocode)>0):\n",
    "                    rg_country_code = rgeocode[0]['country_code']\n",
    "                    rg_city = rgeocode[0]['city']\n",
    "                    rg_country = rgeocode[0]['country']\n",
    "            \n",
    "            #\n",
    "            # GEO_QUAL calc\n",
    "            #\n",
    "            \n",
    "            thr_prec = 2\n",
    "            if ((latitude is not None) & (longitude is not None)):\n",
    "                if ((latitude_precision > thr_prec) | (longitude_precision > thr_prec)):\n",
    "                    geo_qual = 1\n",
    "                else:\n",
    "                    geo_qual = 2\n",
    "            elif (((latitude is None) | (longitude is None)) & (not country_is_na(geo_loc_name_country_calc))):\n",
    "                geo_qual = 3\n",
    "            \n",
    "        # append result\n",
    "        array_result.append([bioproject,acc,organism,assay_type,instrument,librarylayout,libraryselection,librarysource,geo_loc_name_country_calc,geo_loc_name_country_continent_calc,mbytes,mbases,releasedate,collection_date,lat_lon_src,lat_lon_raw,latitude,longitude,latitude_precision,has_latlon,longitude_precision,rg_country_code,rg_city,rg_country,geo_qual])\n",
    "\n",
    "    columns = ['bioproject', 'acc','organism','assay_type','instrument','librarylayout','libraryselection','librarysource','geo_loc_name_country_calc','geo_loc_name_country_continent_calc','mbytes','mbases','releasedate', 'collection_date','lat_lon_src','lat_lon_raw','latitude','longitude','latitude_precision','has_latlon','longitude_precision','rg_country_code','rg_city','rg_country','GEO_QUAL']\n",
    "    dtype = [str,str,str,str,str,str,str,str,str,str,int,int,datetime.date,datetime.date,str,str,float,float,float,float,bool,str,str,str,int]\n",
    "    cdt={i[0]: i[1] for i in zip(columns, dtype)}        \n",
    "    pd_result = pd.DataFrame(data=array_result,columns=list(cdt))\n",
    "\n",
    "    return pd_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bioproject</th>\n",
       "      <th>latitude</th>\n",
       "      <th>latitude_precision</th>\n",
       "      <th>longitude</th>\n",
       "      <th>longitude_precision</th>\n",
       "      <th>geo_loc_name_country_calc</th>\n",
       "      <th>GEO_QUAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRJNA701021</td>\n",
       "      <td>55.226417</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-77.695722</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRJNA291529</td>\n",
       "      <td>61.130000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.240000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Finland</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRJNA780327</td>\n",
       "      <td>40.488160</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-74.426730</td>\n",
       "      <td>5.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRJNA701021</td>\n",
       "      <td>55.226528</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-77.696917</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRJNA799127</td>\n",
       "      <td>44.019600</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-92.481100</td>\n",
       "      <td>4.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52224</th>\n",
       "      <td>PRJNA237344</td>\n",
       "      <td>12.410000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-52.220000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>uncalculated</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52225</th>\n",
       "      <td>PRJNA498721</td>\n",
       "      <td>30.653210</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-87.792099</td>\n",
       "      <td>6.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52226</th>\n",
       "      <td>PRJNA498721</td>\n",
       "      <td>30.618544</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-87.784645</td>\n",
       "      <td>6.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52227</th>\n",
       "      <td>PRJNA498721</td>\n",
       "      <td>30.653210</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-87.792099</td>\n",
       "      <td>6.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52228</th>\n",
       "      <td>PRJNA773504</td>\n",
       "      <td>37.147763</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-93.236811</td>\n",
       "      <td>6.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313377 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bioproject   latitude  latitude_precision  longitude  \\\n",
       "0      PRJNA701021  55.226417                 6.0 -77.695722   \n",
       "1      PRJNA291529  61.130000                 2.0  25.240000   \n",
       "2      PRJNA780327  40.488160                 5.0 -74.426730   \n",
       "3      PRJNA701021  55.226528                 6.0 -77.696917   \n",
       "4      PRJNA799127  44.019600                 4.0 -92.481100   \n",
       "...            ...        ...                 ...        ...   \n",
       "52224  PRJNA237344  12.410000                 2.0 -52.220000   \n",
       "52225  PRJNA498721  30.653210                 5.0 -87.792099   \n",
       "52226  PRJNA498721  30.618544                 6.0 -87.784645   \n",
       "52227  PRJNA498721  30.653210                 5.0 -87.792099   \n",
       "52228  PRJNA773504  37.147763                 6.0 -93.236811   \n",
       "\n",
       "       longitude_precision geo_loc_name_country_calc  GEO_QUAL  \n",
       "0                      6.0                    Canada         1  \n",
       "1                      2.0                   Finland         2  \n",
       "2                      5.0                       USA         1  \n",
       "3                      6.0                    Canada         1  \n",
       "4                      4.0                       USA         1  \n",
       "...                    ...                       ...       ...  \n",
       "52224                  2.0              uncalculated         2  \n",
       "52225                  6.0                       USA         1  \n",
       "52226                  6.0                       USA         1  \n",
       "52227                  6.0                       USA         1  \n",
       "52228                  6.0                       USA         1  \n",
       "\n",
       "[313377 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_output = dask.map_partitions(parse_geo_sra, meta=meta_df).compute(scheduler='multiprocessing')\n",
    "pd_output[[\"bioproject\",\"latitude\",\"latitude_precision\",\"longitude\",\"longitude_precision\",\"geo_loc_name_country_calc\",\"GEO_QUAL\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GEO_QUAL\n",
       "1    180606\n",
       "2     75995\n",
       "3     35226\n",
       "4     21550\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_output[\"GEO_QUAL\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bioproject</th>\n",
       "      <th>acc</th>\n",
       "      <th>organism</th>\n",
       "      <th>assay_type</th>\n",
       "      <th>instrument</th>\n",
       "      <th>librarylayout</th>\n",
       "      <th>libraryselection</th>\n",
       "      <th>librarysource</th>\n",
       "      <th>geo_loc_name_country_calc</th>\n",
       "      <th>geo_loc_name_country_continent_calc</th>\n",
       "      <th>...</th>\n",
       "      <th>lat_lon_raw</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude_precision</th>\n",
       "      <th>has_latlon</th>\n",
       "      <th>longitude_precision</th>\n",
       "      <th>rg_country_code</th>\n",
       "      <th>rg_city</th>\n",
       "      <th>rg_country</th>\n",
       "      <th>GEO_QUAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRJNA701021</td>\n",
       "      <td>SRR13668983</td>\n",
       "      <td>aquatic metagenome</td>\n",
       "      <td>AMPLICON</td>\n",
       "      <td>Sequel</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>PCR</td>\n",
       "      <td>METAGENOMIC</td>\n",
       "      <td>Canada</td>\n",
       "      <td>North America</td>\n",
       "      <td>...</td>\n",
       "      <td>55.226417 N 77.695722 W</td>\n",
       "      <td>55.226417</td>\n",
       "      <td>-77.695722</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>Waskaganish</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRJNA780327</td>\n",
       "      <td>SRR16943517</td>\n",
       "      <td>aquatic metagenome</td>\n",
       "      <td>AMPLICON</td>\n",
       "      <td>MinION</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>PCR</td>\n",
       "      <td>METAGENOMIC</td>\n",
       "      <td>USA</td>\n",
       "      <td>North America</td>\n",
       "      <td>...</td>\n",
       "      <td>40.48816 N 74.42673 W</td>\n",
       "      <td>40.488160</td>\n",
       "      <td>-74.426730</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Highland Park</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRJNA701021</td>\n",
       "      <td>SRR13669015</td>\n",
       "      <td>aquatic metagenome</td>\n",
       "      <td>AMPLICON</td>\n",
       "      <td>Sequel</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>PCR</td>\n",
       "      <td>METAGENOMIC</td>\n",
       "      <td>Canada</td>\n",
       "      <td>North America</td>\n",
       "      <td>...</td>\n",
       "      <td>55.226528 N 77.696917 W</td>\n",
       "      <td>55.226528</td>\n",
       "      <td>-77.696917</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>Waskaganish</td>\n",
       "      <td>Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRJNA799127</td>\n",
       "      <td>SRR17734756</td>\n",
       "      <td>freshwater metagenome</td>\n",
       "      <td>WGS</td>\n",
       "      <td>GridION</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>RANDOM</td>\n",
       "      <td>GENOMIC</td>\n",
       "      <td>USA</td>\n",
       "      <td>North America</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0196 N 92.4811 W</td>\n",
       "      <td>44.019600</td>\n",
       "      <td>-92.481100</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Rochester</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PRJNA591360</td>\n",
       "      <td>SRR10522099</td>\n",
       "      <td>freshwater metagenome</td>\n",
       "      <td>AMPLICON</td>\n",
       "      <td>454 GS</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>PCR</td>\n",
       "      <td>METAGENOMIC</td>\n",
       "      <td>USA</td>\n",
       "      <td>North America</td>\n",
       "      <td>...</td>\n",
       "      <td>47.60583 N 86.81778 W</td>\n",
       "      <td>47.605830</td>\n",
       "      <td>-86.817780</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Munising</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52222</th>\n",
       "      <td>PRJNA498721</td>\n",
       "      <td>SRR8127881</td>\n",
       "      <td>freshwater metagenome</td>\n",
       "      <td>AMPLICON</td>\n",
       "      <td>Illumina Genome Analyzer</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>PCR</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>USA</td>\n",
       "      <td>North America</td>\n",
       "      <td>...</td>\n",
       "      <td>30.618544 N 87.784645 W</td>\n",
       "      <td>30.618544</td>\n",
       "      <td>-87.784645</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Loxley</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52225</th>\n",
       "      <td>PRJNA498721</td>\n",
       "      <td>SRR8127947</td>\n",
       "      <td>freshwater metagenome</td>\n",
       "      <td>AMPLICON</td>\n",
       "      <td>Illumina Genome Analyzer</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>PCR</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>USA</td>\n",
       "      <td>North America</td>\n",
       "      <td>...</td>\n",
       "      <td>30.65321 N 87.792099 W</td>\n",
       "      <td>30.653210</td>\n",
       "      <td>-87.792099</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Loxley</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52226</th>\n",
       "      <td>PRJNA498721</td>\n",
       "      <td>SRR8127884</td>\n",
       "      <td>freshwater metagenome</td>\n",
       "      <td>AMPLICON</td>\n",
       "      <td>Illumina Genome Analyzer</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>PCR</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>USA</td>\n",
       "      <td>North America</td>\n",
       "      <td>...</td>\n",
       "      <td>30.618544 N 87.784645 W</td>\n",
       "      <td>30.618544</td>\n",
       "      <td>-87.784645</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Loxley</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52227</th>\n",
       "      <td>PRJNA498721</td>\n",
       "      <td>SRR8127887</td>\n",
       "      <td>freshwater metagenome</td>\n",
       "      <td>AMPLICON</td>\n",
       "      <td>Illumina Genome Analyzer</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>PCR</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>USA</td>\n",
       "      <td>North America</td>\n",
       "      <td>...</td>\n",
       "      <td>30.65321 N 87.792099 W</td>\n",
       "      <td>30.653210</td>\n",
       "      <td>-87.792099</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Loxley</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52228</th>\n",
       "      <td>PRJNA773504</td>\n",
       "      <td>SRR16547782</td>\n",
       "      <td>freshwater metagenome</td>\n",
       "      <td>AMPLICON</td>\n",
       "      <td>Illumina Genome Analyzer</td>\n",
       "      <td>PAIRED</td>\n",
       "      <td>PCR</td>\n",
       "      <td>METAGENOMIC</td>\n",
       "      <td>USA</td>\n",
       "      <td>North America</td>\n",
       "      <td>...</td>\n",
       "      <td>37.147763 N 93.236811 W</td>\n",
       "      <td>37.147763</td>\n",
       "      <td>-93.236811</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180606 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bioproject          acc               organism assay_type  \\\n",
       "0      PRJNA701021  SRR13668983     aquatic metagenome   AMPLICON   \n",
       "2      PRJNA780327  SRR16943517     aquatic metagenome   AMPLICON   \n",
       "3      PRJNA701021  SRR13669015     aquatic metagenome   AMPLICON   \n",
       "4      PRJNA799127  SRR17734756  freshwater metagenome        WGS   \n",
       "5      PRJNA591360  SRR10522099  freshwater metagenome   AMPLICON   \n",
       "...            ...          ...                    ...        ...   \n",
       "52222  PRJNA498721   SRR8127881  freshwater metagenome   AMPLICON   \n",
       "52225  PRJNA498721   SRR8127947  freshwater metagenome   AMPLICON   \n",
       "52226  PRJNA498721   SRR8127884  freshwater metagenome   AMPLICON   \n",
       "52227  PRJNA498721   SRR8127887  freshwater metagenome   AMPLICON   \n",
       "52228  PRJNA773504  SRR16547782  freshwater metagenome   AMPLICON   \n",
       "\n",
       "                     instrument librarylayout libraryselection librarysource  \\\n",
       "0                        Sequel        SINGLE              PCR   METAGENOMIC   \n",
       "2                        MinION        SINGLE              PCR   METAGENOMIC   \n",
       "3                        Sequel        SINGLE              PCR   METAGENOMIC   \n",
       "4                       GridION        SINGLE           RANDOM       GENOMIC   \n",
       "5                        454 GS        SINGLE              PCR   METAGENOMIC   \n",
       "...                         ...           ...              ...           ...   \n",
       "52222  Illumina Genome Analyzer        PAIRED              PCR         OTHER   \n",
       "52225  Illumina Genome Analyzer        PAIRED              PCR         OTHER   \n",
       "52226  Illumina Genome Analyzer        PAIRED              PCR         OTHER   \n",
       "52227  Illumina Genome Analyzer        PAIRED              PCR         OTHER   \n",
       "52228  Illumina Genome Analyzer        PAIRED              PCR   METAGENOMIC   \n",
       "\n",
       "      geo_loc_name_country_calc geo_loc_name_country_continent_calc  ...  \\\n",
       "0                        Canada                       North America  ...   \n",
       "2                           USA                       North America  ...   \n",
       "3                        Canada                       North America  ...   \n",
       "4                           USA                       North America  ...   \n",
       "5                           USA                       North America  ...   \n",
       "...                         ...                                 ...  ...   \n",
       "52222                       USA                       North America  ...   \n",
       "52225                       USA                       North America  ...   \n",
       "52226                       USA                       North America  ...   \n",
       "52227                       USA                       North America  ...   \n",
       "52228                       USA                       North America  ...   \n",
       "\n",
       "                   lat_lon_raw   latitude  longitude latitude_precision  \\\n",
       "0      55.226417 N 77.695722 W  55.226417 -77.695722                6.0   \n",
       "2        40.48816 N 74.42673 W  40.488160 -74.426730                5.0   \n",
       "3      55.226528 N 77.696917 W  55.226528 -77.696917                6.0   \n",
       "4          44.0196 N 92.4811 W  44.019600 -92.481100                4.0   \n",
       "5        47.60583 N 86.81778 W  47.605830 -86.817780                5.0   \n",
       "...                        ...        ...        ...                ...   \n",
       "52222  30.618544 N 87.784645 W  30.618544 -87.784645                6.0   \n",
       "52225   30.65321 N 87.792099 W  30.653210 -87.792099                5.0   \n",
       "52226  30.618544 N 87.784645 W  30.618544 -87.784645                6.0   \n",
       "52227   30.65321 N 87.792099 W  30.653210 -87.792099                5.0   \n",
       "52228  37.147763 N 93.236811 W  37.147763 -93.236811                6.0   \n",
       "\n",
       "      has_latlon longitude_precision  rg_country_code        rg_city  \\\n",
       "0           True                 6.0               CA    Waskaganish   \n",
       "2           True                 5.0               US  Highland Park   \n",
       "3           True                 6.0               CA    Waskaganish   \n",
       "4           True                 4.0               US      Rochester   \n",
       "5           True                 5.0               US       Munising   \n",
       "...          ...                 ...              ...            ...   \n",
       "52222       True                 6.0               US         Loxley   \n",
       "52225       True                 6.0               US         Loxley   \n",
       "52226       True                 6.0               US         Loxley   \n",
       "52227       True                 6.0               US         Loxley   \n",
       "52228       True                 6.0               US    Springfield   \n",
       "\n",
       "          rg_country  GEO_QUAL  \n",
       "0             Canada         1  \n",
       "2      United States         1  \n",
       "3             Canada         1  \n",
       "4      United States         1  \n",
       "5      United States         1  \n",
       "...              ...       ...  \n",
       "52222  United States         1  \n",
       "52225  United States         1  \n",
       "52226  United States         1  \n",
       "52227  United States         1  \n",
       "52228  United States         1  \n",
       "\n",
       "[180606 rows x 25 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_output[pd_output[\"GEO_QUAL\"] == 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
